# Dockerfile para Proyecto 2 - PySpark

FROM python:3.11-slim

# Instalar Java (requerido por Spark)
RUN apt-get update && \
    apt-get install -y openjdk-11-jdk wget && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

# Configurar JAVA_HOME
ENV JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
ENV PATH="${JAVA_HOME}/bin:${PATH}"

# Crear directorio de trabajo
WORKDIR /app

# Copiar requirements
COPY requirements.txt .

# Instalar dependencias Python
RUN pip install --no-cache-dir -r requirements.txt

# Copiar c√≥digo del proyecto
COPY . .

# Crear directorios necesarios
RUN mkdir -p datos resultados docs

# Comando por defecto
CMD ["python", "analisis_clima_pyspark.py"]