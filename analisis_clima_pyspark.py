"""
Proyecto 2 - AnÃ¡lisis de Datos ClimÃ¡ticos con PySpark
Dataset: NOAA Climate Data (GHCN-Daily)
"""

from pyspark.sql import SparkSession
from pyspark.sql.functions import *
from pyspark.sql.types import *
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from pathlib import Path

# Importar configuraciÃ³n
from config import (
    DATOS_PROCESADOS,
    RESULTADOS_DIR,
    SPARK_CONFIG,
    GRAFICAS_CONFIG
)
from utils import imprimir_banner, limpiar_archivos_temporales

# Configurar estilo de grÃ¡ficas
plt.style.use('seaborn-v0_8-darkgrid')


def inicializar_spark():
    """Inicializa y configura Spark Session"""
    print("ðŸš€ Inicializando Apache Spark...")
    
    spark = SparkSession.builder \
        .appName(SPARK_CONFIG['app_name']) \
        .config("spark.driver.memory", SPARK_CONFIG['driver_memory']) \
        .config("spark.sql.shuffle.partitions", "10") \
        .getOrCreate()
    
    # Reducir verbosidad de logs
    spark.sparkContext.setLogLevel(SPARK_CONFIG['log_level'])
    
    print(f"âœ… Spark {spark.version} iniciado")
    print(f"   App: {SPARK_CONFIG['app_name']}")
    print(f"   Memoria: {SPARK_CONFIG['driver_memory']}")
    
    return spark


def cargar_datos(spark, filepath):
    """
    Carga datos desde CSV a PySpark DataFrame
    
    Args:
        spark: SparkSession
        filepath: Path del archivo CSV
        
    Returns:
        DataFrame de PySpark
    """
    imprimir_banner("CARGA DE DATOS")
    
    print(f"\nðŸ“‚ Archivo: {filepath}")
    
    # Leer CSV
    df = spark.read.csv(str(filepath), header=True, inferSchema=True)
    
    # InformaciÃ³n bÃ¡sica
    print(f"\nðŸ“Š InformaciÃ³n del dataset:")
    print(f"   - Total registros: {df.count():,}")
    print(f"   - Columnas: {len(df.columns)}")
    
    print("\nðŸ“‹ Esquema de datos:")
    df.printSchema()
    
    print("\nðŸ” Muestra de datos:")
    df.show(5, truncate=False)
    
    return df


def procesamiento_1_temperatura_mensual(df):
    """
    PROCESAMIENTO 1: Temperatura Promedio Mensual
    Calcula estadÃ­sticas mensuales de temperatura por estaciÃ³n
    """
    imprimir_banner("PROCESAMIENTO 1: TEMPERATURA MENSUAL")
    
    # AgregaciÃ³n con PySpark
    temp_mensual = df.groupBy("STATION", "YEAR", "MONTH") \
        .agg(
            avg("TEMP").alias("temp_promedio"),
            max("TEMP").alias("temp_maxima"),
            min("TEMP").alias("temp_minima"),
            stddev("TEMP").alias("desv_std"),
            count("*").alias("num_registros")
        ) \
        .orderBy("YEAR", "MONTH")
    
    print("\nðŸ“ˆ Resultados:")
    temp_mensual.show(15)
    
    # Convertir a Pandas solo los datos agregados (pequeÃ±os)
    temp_pandas = temp_mensual.toPandas()
    
    # Crear Ã­ndice temporal para graficar
    temp_pandas['periodo'] = temp_pandas['YEAR'].astype(str) + '-' + temp_pandas['MONTH'].astype(str).str.zfill(2)
    
    # Graficar
    plt.figure(figsize=GRAFICAS_CONFIG['figsize_default'])
    
    # Tomar solo primeras estaciones para legibilidad
    estaciones_top = temp_pandas['STATION'].unique()[:3]
    
    for estacion in estaciones_top:
        data = temp_pandas[temp_pandas['STATION'] == estacion].head(50)
        plt.plot(range(len(data)), data['temp_promedio'], 
                marker='o', linewidth=2, markersize=3, label=estacion, alpha=0.7)
    
    plt.title('Temperatura Promedio Mensual por EstaciÃ³n', fontsize=14, fontweight='bold')
    plt.xlabel('PerÃ­odo (meses)')
    plt.ylabel('Temperatura (Â°C)')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    
    output_path = RESULTADOS_DIR / 'grafica_1_temp_mensual.png'
    plt.savefig(output_path, dpi=GRAFICAS_CONFIG['dpi'])
    plt.close()
    
    print(f"\nâœ… GrÃ¡fica guardada: {output_path}")
    
    return temp_mensual


def procesamiento_2_precipitacion_anual(df):
    """
    PROCESAMIENTO 2: PrecipitaciÃ³n Anual
    Calcula estadÃ­sticas anuales de precipitaciÃ³n
    """
    imprimir_banner("PROCESAMIENTO 2: PRECIPITACIÃ“N ANUAL")
    
    # AgregaciÃ³n con PySpark
    precip_anual = df.groupBy("YEAR") \
        .agg(
            sum("PRCP").alias("precip_total"),
            avg("PRCP").alias("precip_promedio"),
            stddev("PRCP").alias("desviacion_std"),
            max("PRCP").alias("precip_maxima"),
            count("*").alias("num_registros")
        ) \
        .orderBy("YEAR")
    
    print("\nðŸ“Š Resultados:")
    precip_anual.show()
    
    # Convertir a Pandas
    precip_pandas = precip_anual.toPandas()
    
    # Crear figura con dos subgrÃ¡ficas
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=GRAFICAS_CONFIG['figsize_large'])
    
    # GrÃ¡fica 1: PrecipitaciÃ³n total anual
    ax1.bar(precip_pandas['YEAR'], precip_pandas['precip_total'], 
            color='steelblue', alpha=0.7, edgecolor='black')
    ax1.set_title('PrecipitaciÃ³n Total Anual', fontsize=14, fontweight='bold')
    ax1.set_ylabel('PrecipitaciÃ³n Total (mm)')
    ax1.grid(True, alpha=0.3, axis='y')
    
    # GrÃ¡fica 2: DesviaciÃ³n estÃ¡ndar
    ax2.plot(precip_pandas['YEAR'], precip_pandas['desviacion_std'], 
             marker='s', color='coral', linewidth=2, markersize=6)
    ax2.set_title('Variabilidad de PrecipitaciÃ³n (DesviaciÃ³n EstÃ¡ndar)', 
                  fontsize=14, fontweight='bold')
    ax2.set_xlabel('AÃ±o')
    ax2.set_ylabel('DesviaciÃ³n EstÃ¡ndar (mm)')
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    output_path = RESULTADOS_DIR / 'grafica_2_precipitacion.png'
    plt.savefig(output_path, dpi=GRAFICAS_CONFIG['dpi'])
    plt.close()
    
    print(f"\nâœ… GrÃ¡fica guardada: {output_path}")
    
    return precip_anual


def procesamiento_3_extremos_climaticos(df):
    """
    PROCESAMIENTO 3: Extremos ClimÃ¡ticos por EstaciÃ³n
    Identifica rÃ©cords de temperatura y precipitaciÃ³n
    """
    imprimir_banner("PROCESAMIENTO 3: EXTREMOS CLIMÃTICOS")
    
    # AgregaciÃ³n con PySpark
    extremos = df.groupBy("STATION") \
        .agg(
            max("TEMP").alias("temp_record_max"),
            min("TEMP").alias("temp_record_min"),
            max("PRCP").alias("precip_record"),
            avg("TEMP").alias("temp_media"),
            count("*").alias("num_observaciones")
        ) \
        .orderBy(desc("temp_record_max"))
    
    print("\nðŸŒ¡ï¸  Resultados (Top 10 estaciones):")
    extremos.show(10, truncate=False)
    
    # Convertir a Pandas
    extremos_pandas = extremos.toPandas().head(10)
    
    # Graficar temperaturas extremas
    x = np.arange(len(extremos_pandas))
    width = 0.35
    
    fig, ax = plt.subplots(figsize=GRAFICAS_CONFIG['figsize_default'])
    
    bars1 = ax.bar(x - width/2, extremos_pandas['temp_record_max'], width, 
                   label='Temp. MÃ¡xima', color='red', alpha=0.7, edgecolor='black')
    bars2 = ax.bar(x + width/2, extremos_pandas['temp_record_min'], width, 
                   label='Temp. MÃ­nima', color='blue', alpha=0.7, edgecolor='black')
    
    ax.set_xlabel('EstaciÃ³n MeteorolÃ³gica')
    ax.set_ylabel('Temperatura (Â°C)')
    ax.set_title('Temperaturas Extremas por EstaciÃ³n', fontsize=14, fontweight='bold')
    ax.set_xticks(x)
    ax.set_xticklabels([f'Est-{i+1}' for i in range(len(extremos_pandas))], rotation=45)
    ax.legend()
    ax.grid(True, alpha=0.3, axis='y')
    ax.axhline(y=0, color='black', linestyle='-', linewidth=0.5)
    
    plt.tight_layout()
    output_path = RESULTADOS_DIR / 'grafica_3_extremos.png'
    plt.savefig(output_path, dpi=GRAFICAS_CONFIG['dpi'])
    plt.close()
    
    print(f"\nâœ… GrÃ¡fica guardada: {output_path}")
    
    return extremos


def procesamiento_4_analisis_estacional(df):
    """
    PROCESAMIENTO 4: AnÃ¡lisis Estacional
    Compara variables climÃ¡ticas por estaciÃ³n del aÃ±o
    """
    imprimir_banner("PROCESAMIENTO 4: ANÃLISIS ESTACIONAL")
    
    # Definir estaciones del aÃ±o con PySpark
    df_season = df.withColumn("SEASON", 
        when((col("MONTH") >= 3) & (col("MONTH") <= 5), "Primavera")
        .when((col("MONTH") >= 6) & (col("MONTH") <= 8), "Verano")
        .when((col("MONTH") >= 9) & (col("MONTH") <= 11), "OtoÃ±o")
        .otherwise("Invierno")
    )
    
    # AgregaciÃ³n
    estacional = df_season.groupBy("SEASON") \
        .agg(
            avg("TEMP").alias("temp_promedio"),
            avg("PRCP").alias("precip_promedio"),
            max("TEMP").alias("temp_maxima"),
            min("TEMP").alias("temp_minima"),
            count("*").alias("num_observaciones")
        )
    
    print("\nðŸ‚ Resultados por estaciÃ³n del aÃ±o:")
    estacional.show()
    
    # Convertir a Pandas
    estacional_pandas = estacional.toPandas()
    
    # Ordenar estaciones cronolÃ³gicamente
    orden_estaciones = ['Primavera', 'Verano', 'OtoÃ±o', 'Invierno']
    estacional_pandas['SEASON'] = pd.Categorical(
        estacional_pandas['SEASON'], 
        categories=orden_estaciones, 
        ordered=True
    )
    estacional_pandas = estacional_pandas.sort_values('SEASON')
    
    # Crear figura con dos subgrÃ¡ficas
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=GRAFICAS_CONFIG['figsize_large'])
    
    colores = ['#90EE90', '#FFD700', '#FF8C00', '#4682B4']
    
    # Temperatura por estaciÃ³n
    bars1 = ax1.bar(estacional_pandas['SEASON'], estacional_pandas['temp_promedio'], 
                    color=colores, alpha=0.7, edgecolor='black')
    ax1.set_title('Temperatura Promedio\npor EstaciÃ³n del AÃ±o', fontsize=13, fontweight='bold')
    ax1.set_ylabel('Temperatura (Â°C)')
    ax1.grid(True, alpha=0.3, axis='y')
    ax1.tick_params(axis='x', rotation=15)
    
    # AÃ±adir valores en las barras
    for bar in bars1:
        height = bar.get_height()
        ax1.text(bar.get_x() + bar.get_width()/2., height,
                f'{height:.1f}Â°C', ha='center', va='bottom', fontsize=10)
    
    # PrecipitaciÃ³n por estaciÃ³n
    bars2 = ax2.bar(estacional_pandas['SEASON'], estacional_pandas['precip_promedio'], 
                    color=colores, alpha=0.7, edgecolor='black')
    ax2.set_title('PrecipitaciÃ³n Promedio\npor EstaciÃ³n del AÃ±o', fontsize=13, fontweight='bold')
    ax2.set_ylabel('PrecipitaciÃ³n (mm/dÃ­a)')
    ax2.grid(True, alpha=0.3, axis='y')
    ax2.tick_params(axis='x', rotation=15)
    
    # AÃ±adir valores en las barras
    for bar in bars2:
        height = bar.get_height()
        ax2.text(bar.get_x() + bar.get_width()/2., height,
                f'{height:.2f}mm', ha='center', va='bottom', fontsize=10)
    
    plt.tight_layout()
    output_path = RESULTADOS_DIR / 'grafica_4_estacional.png'
    plt.savefig(output_path, dpi=GRAFICAS_CONFIG['dpi'])
    plt.close()
    
    print(f"\nâœ… GrÃ¡fica guardada: {output_path}")
    
    return estacional


def procesamiento_5_tendencia_correlacion(df):
    """
    PROCESAMIENTO 5: Tendencia Temporal y CorrelaciÃ³n
    Analiza evoluciÃ³n temporal y relaciÃ³n entre variables
    """
    imprimir_banner("PROCESAMIENTO 5: TENDENCIAS Y CORRELACIÃ“N")
    
    # Tendencia anual
    tendencia = df.groupBy("YEAR") \
        .agg(
            avg("TEMP").alias("temp_anual"),
            avg("PRCP").alias("precip_anual"),
            count("*").alias("num_registros")
        ) \
        .orderBy("YEAR")
    
    print("\nðŸ“ˆ Tendencia anual:")
    tendencia.show()
    
    # Calcular correlaciÃ³n con PySpark
    correlacion = df.stat.corr("TEMP", "PRCP")
    print(f"\nðŸ”— Coeficiente de CorrelaciÃ³n Temperatura-PrecipitaciÃ³n: {correlacion:.4f}")
    
    # InterpretaciÃ³n
    if abs(correlacion) < 0.3:
        interpretacion = "dÃ©bil"
    elif abs(correlacion) < 0.7:
        interpretacion = "moderada"
    else:
        interpretacion = "fuerte"
    
    print(f"   InterpretaciÃ³n: CorrelaciÃ³n {interpretacion}")
    
    # Convertir a Pandas
    tendencia_pandas = tendencia.toPandas()
    
    # Crear grÃ¡fica de doble eje Y
    fig, ax1 = plt.subplots(figsize=GRAFICAS_CONFIG['figsize_default'])
    
    color1 = 'tab:red'
    ax1.set_xlabel('AÃ±o', fontsize=12)
    ax1.set_ylabel('Temperatura Promedio (Â°C)', color=color1, fontsize=12)
    line1 = ax1.plot(tendencia_pandas['YEAR'], tendencia_pandas['temp_anual'], 
                     color=color1, marker='o', linewidth=2.5, markersize=6, 
                     label='Temperatura', alpha=0.8)
    ax1.tick_params(axis='y', labelcolor=color1)
    ax1.grid(True, alpha=0.3)
    
    # Segundo eje Y
    ax2 = ax1.twinx()
    color2 = 'tab:blue'
    ax2.set_ylabel('PrecipitaciÃ³n Promedio (mm/dÃ­a)', color=color2, fontsize=12)
    line2 = ax2.plot(tendencia_pandas['YEAR'], tendencia_pandas['precip_anual'], 
                     color=color2, marker='s', linewidth=2.5, markersize=6, 
                     label='PrecipitaciÃ³n', alpha=0.8)
    ax2.tick_params(axis='y', labelcolor=color2)
    
    # TÃ­tulo con correlaciÃ³n
    plt.title(f'Tendencia Temporal: Temperatura vs PrecipitaciÃ³n\n(CorrelaciÃ³n: {correlacion:.3f})', 
              fontsize=14, fontweight='bold', pad=20)
    
    # Leyenda combinada
    lines = line1 + line2
    labels = [l.get_label() for l in lines]
    ax1.legend(lines, labels, loc='upper left')
    
    fig.tight_layout()
    output_path = RESULTADOS_DIR / 'grafica_5_tendencia.png'
    plt.savefig(output_path, dpi=GRAFICAS_CONFIG['dpi'])
    plt.close()
    
    print(f"\nâœ… GrÃ¡fica guardada: {output_path}")
    
    return tendencia, correlacion


def main():
    """FunciÃ³n principal"""
    print("\n" + "âš¡" * 30)
    print("PROYECTO 2 - ANÃLISIS CLIMÃTICO CON PYSPARK".center(60))
    print("âš¡" * 30 + "\n")
    
    try:
        # Verificar que existen los datos
        if not DATOS_PROCESADOS.exists():
            print(f"âŒ Archivo no encontrado: {DATOS_PROCESADOS}")
            print("\nâš ï¸  Primero ejecuta: python descargar_datos_noaa.py")
            return
        
        # 1. Inicializar Spark
        spark = inicializar_spark()
        
        # 2. Cargar datos
        df = cargar_datos(spark, DATOS_PROCESADOS)
        
        # 3. Ejecutar los 5 procesamientos
        print("\n" + "="*60)
        print("EJECUTANDO 5 PROCESAMIENTOS")
        print("="*60)
        
        resultado1 = procesamiento_1_temperatura_mensual(df)
        resultado2 = procesamiento_2_precipitacion_anual(df)
        resultado3 = procesamiento_3_extremos_climaticos(df)
        resultado4 = procesamiento_4_analisis_estacional(df)
        resultado5, correlacion = procesamiento_5_tendencia_correlacion(df)
        
        # 4. Resumen final
        imprimir_banner("âœ… ANÃLISIS COMPLETADO")
        
        print(f"\nðŸ“Š Resumen de resultados:")
        print(f"   - Total de registros procesados: {df.count():,}")
        print(f"   - Procesamiento completados: 5/5")
        print(f"   - GrÃ¡ficas generadas: 5")
        print(f"   - Directorio de resultados: {RESULTADOS_DIR}")
        
        print(f"\nðŸ“ˆ EstadÃ­sticas generales:")
        df.select(
            avg("TEMP").alias("temp_promedio"),
            max("TEMP").alias("temp_maxima"),
            min("TEMP").alias("temp_minima"),
            avg("PRCP").alias("precip_promedio")
        ).show()
        
        print(f"\nðŸŽ¯ PrÃ³ximos pasos:")
        print(f"   1. Revisar grÃ¡ficas en: {RESULTADOS_DIR}/")
        print(f"   2. Incluir resultados en el documento Word")
        print(f"   3. Preparar presentaciÃ³n con las grÃ¡ficas")
        print(f"   4. Generar muestra 5% para entrega")
        
        # 5. Cerrar Spark
        spark.stop()
        print(f"\nâœ… SesiÃ³n Spark finalizada")
        
        # 6. Limpiar archivos temporales
        limpiar_archivos_temporales()
        
    except Exception as e:
        print(f"\nâŒ Error durante el anÃ¡lisis: {e}")
        import traceback
        traceback.print_exc()
    
    print("\n" + "ðŸŽ‰" * 30)
    print("FIN DEL ANÃLISIS".center(60))
    print("ðŸŽ‰" * 30 + "\n")


if __name__ == "__main__":
    main()