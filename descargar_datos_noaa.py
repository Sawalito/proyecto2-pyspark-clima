"""
Script para descargar datos clim√°ticos de NOAA
Dataset: Global Historical Climatology Network (GHCN-Daily)
"""

import requests
import os
import pandas as pd
from pathlib import Path
from config import (
    DATOS_DIR, 
    ESTACIONES_NOAA, 
    NOAA_BASE_URL,
    DATOS_CRUDOS,
    DATOS_PROCESADOS,
    REQUISITOS
)
from utils import (
    imprimir_banner,
    verificar_tama√±o_archivo,
    listar_archivos_datos
)


def descargar_estacion(estacion, output_dir):
    """
    Descarga datos de una estaci√≥n espec√≠fica
    
    Args:
        estacion: C√≥digo de estaci√≥n NOAA
        output_dir: Directorio de salida
        
    Returns:
        str: Path del archivo descargado o None si fall√≥
    """
    try:
        url = f"{NOAA_BASE_URL}{estacion}.csv"
        filename = output_dir / f"{estacion}.csv"
        
        print(f"üì• Descargando {estacion}...", end=" ", flush=True)
        
        response = requests.get(url, stream=True, timeout=60)
        
        if response.status_code == 200:
            with open(filename, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    f.write(chunk)
            
            tama√±o_mb = os.path.getsize(filename) / (1024 * 1024)
            print(f"‚úÖ ({tama√±o_mb:.1f} MB)")
            return filename
        else:
            print(f"‚ùå Error {response.status_code}")
            return None
            
    except Exception as e:
        print(f"‚ùå Error: {str(e)}")
        return None


def descargar_todas_estaciones():
    """
    Descarga datos de todas las estaciones configuradas
    
    Returns:
        list: Lista de archivos descargados
    """
    imprimir_banner("DESCARGA DE DATOS NOAA")
    
    # Crear directorio para datos crudos
    datos_noaa_dir = DATOS_DIR / "datos_noaa"
    datos_noaa_dir.mkdir(exist_ok=True)
    
    print(f"\nüìç Descargando {len(ESTACIONES_NOAA)} estaciones meteorol√≥gicas")
    print(f"üìÇ Destino: {datos_noaa_dir}\n")
    
    archivos_descargados = []
    
    for idx, estacion in enumerate(ESTACIONES_NOAA, 1):
        print(f"[{idx:2d}/{len(ESTACIONES_NOAA)}] ", end="")
        archivo = descargar_estacion(estacion, datos_noaa_dir)
        
        if archivo:
            archivos_descargados.append(archivo)
    
    # Resumen
    imprimir_banner("RESUMEN DE DESCARGA")
    print(f"\n‚úÖ Archivos descargados: {len(archivos_descargados)}/{len(ESTACIONES_NOAA)}")
    
    tama√±o_total_gb = sum(os.path.getsize(f) for f in archivos_descargados) / (1024**3)
    print(f"üìä Tama√±o total: {tama√±o_total_gb:.2f} GB")
    
    if tama√±o_total_gb >= REQUISITOS['tama√±o_minimo_gb']:
        print(f"‚úÖ Cumple requisito m√≠nimo (>{REQUISITOS['tama√±o_minimo_gb']} GB)")
    else:
        print(f"‚ö†Ô∏è  Advertencia: Tama√±o menor a {REQUISITOS['tama√±o_minimo_gb']} GB")
        print("   Considera descargar m√°s estaciones")
    
    return archivos_descargados


def unificar_archivos(archivos):
    """
    Unifica m√∫ltiples archivos CSV en uno solo
    
    Args:
        archivos: Lista de paths a archivos CSV
        
    Returns:
        str: Path del archivo unificado
    """
    if not archivos:
        print("‚ùå No hay archivos para unificar")
        return None
    
    imprimir_banner("UNIFICACI√ìN DE ARCHIVOS")
    
    print(f"\nüîÑ Unificando {len(archivos)} archivos...")
    
    dfs = []
    for archivo in archivos:
        try:
            # Leer solo columnas necesarias para ahorrar memoria
            columnas = ['STATION', 'DATE', 'TMAX', 'TMIN', 'PRCP']
            df = pd.read_csv(archivo, usecols=lambda x: x in columnas)
            dfs.append(df)
            print(f"   ‚úÖ {Path(archivo).name}: {len(df):,} registros")
        except Exception as e:
            print(f"   ‚ùå Error en {Path(archivo).name}: {e}")
    
    if not dfs:
        print("‚ùå No se pudo leer ning√∫n archivo")
        return None
    
    # Combinar todos los DataFrames
    print("\nüîÑ Combinando datos...")
    df_unificado = pd.concat(dfs, ignore_index=True)
    
    # Guardar archivo unificado
    print(f"üíæ Guardando archivo unificado...")
    df_unificado.to_csv(DATOS_CRUDOS, index=False)
    
    print(f"\n‚úÖ Archivo unificado creado: {DATOS_CRUDOS.name}")
    print(f"   üìä Registros totales: {len(df_unificado):,}")
    print(f"   üìÖ Periodo: {df_unificado['DATE'].min()} a {df_unificado['DATE'].max()}")
    print(f"   üìè Columnas: {list(df_unificado.columns)}")
    
    # Verificar tama√±o
    verificar_tama√±o_archivo(DATOS_CRUDOS, REQUISITOS['tama√±o_minimo_gb'])
    
    return DATOS_CRUDOS


def preparar_datos_para_pyspark(archivo):
    """
    Limpia y prepara datos para PySpark
    
    Args:
        archivo: Path del archivo a procesar
        
    Returns:
        str: Path del archivo procesado
    """
    if not archivo or not os.path.exists(archivo):
        print(f"‚ùå Archivo no encontrado: {archivo}")
        return None
    
    imprimir_banner("PREPARACI√ìN PARA PYSPARK")
    
    print("\nüìñ Leyendo datos...")
    df = pd.read_csv(archivo)
    
    print(f"   Registros iniciales: {len(df):,}")
    
    # Limpieza de datos
    print("\nüßπ Limpiando datos...")
    
    # 1. Eliminar filas con valores nulos en columnas cr√≠ticas
    antes = len(df)
    df = df.dropna(subset=['TMAX', 'TMIN', 'PRCP'])
    print(f"   ‚úÖ Eliminadas {antes - len(df):,} filas con valores nulos")
    
    # 2. Convertir fechas y extraer componentes
    print("   üóìÔ∏è  Procesando fechas...")
    df['DATE'] = pd.to_datetime(df['DATE'])
    df['YEAR'] = df['DATE'].dt.year
    df['MONTH'] = df['DATE'].dt.month
    df['DAY'] = df['DATE'].dt.day
    
    # 3. Calcular temperatura promedio
    df['TEMP'] = (df['TMAX'] + df['TMIN']) / 2
    
    # 4. Convertir temperaturas a Celsius (NOAA usa d√©cimas de Celsius)
    df['TMAX'] = df['TMAX'] / 10
    df['TMIN'] = df['TMIN'] / 10
    df['TEMP'] = df['TEMP'] / 10
    
    # 5. Convertir precipitaci√≥n a mm (NOAA usa d√©cimas de mm)
    df['PRCP'] = df['PRCP'] / 10
    
    # Informaci√≥n del dataset procesado
    print(f"\nüìä Dataset procesado:")
    print(f"   - Registros: {len(df):,}")
    print(f"   - Periodo: {df['YEAR'].min()} - {df['YEAR'].max()} ({df['YEAR'].max() - df['YEAR'].min() + 1} a√±os)")
    print(f"   - Estaciones: {df['STATION'].nunique()}")
    print(f"   - Columnas: {list(df.columns)}")
    
    # Estad√≠sticas r√°pidas
    print(f"\nüìà Estad√≠sticas:")
    print(f"   - Temperatura promedio: {df['TEMP'].mean():.1f}¬∞C")
    print(f"   - Temp. m√°xima record: {df['TMAX'].max():.1f}¬∞C")
    print(f"   - Temp. m√≠nima record: {df['TMIN'].min():.1f}¬∞C")
    print(f"   - Precipitaci√≥n promedio: {df['PRCP'].mean():.2f} mm/d√≠a")
    
    # Guardar archivo procesado
    print(f"\nüíæ Guardando datos procesados...")
    df.to_csv(DATOS_PROCESADOS, index=False)
    
    print(f"\n‚úÖ Datos listos para PySpark: {DATOS_PROCESADOS.name}")
    
    return DATOS_PROCESADOS


def main():
    """Funci√≥n principal"""
    print("\n" + "üå§Ô∏è " * 20)
    print("PROYECTO 2 - DESCARGA Y PREPARACI√ìN DE DATOS NOAA".center(80))
    print("üå§Ô∏è " * 20 + "\n")
    
    try:
        # Paso 1: Descargar datos
        print("PASO 1/3: Descarga de datos")
        archivos = descargar_todas_estaciones()
        
        if not archivos:
            print("\n‚ùå No se descargaron archivos. Verifica tu conexi√≥n a internet.")
            return
        
        # Paso 2: Unificar archivos
        print("\n" + "-" * 60)
        print("PASO 2/3: Unificaci√≥n de archivos")
        archivo_unificado = unificar_archivos(archivos)
        
        if not archivo_unificado:
            print("\n‚ùå Error al unificar archivos")
            return
        
        # Paso 3: Preparar para PySpark
        print("\n" + "-" * 60)
        print("PASO 3/3: Preparaci√≥n para PySpark")
        archivo_final = preparar_datos_para_pyspark(archivo_unificado)
        
        if not archivo_final:
            print("\n‚ùå Error al preparar datos")
            return
        
        # Resumen final
        imprimir_banner("‚úÖ PROCESO COMPLETADO")
        print(f"\nüìÅ Archivos generados:")
        print(f"   1. Datos crudos: {DATOS_CRUDOS}")
        print(f"   2. Datos procesados: {DATOS_PROCESADOS}")
        
        print(f"\nüöÄ Pr√≥ximos pasos:")
        print(f"   1. Ejecutar: python analisis_clima_pyspark.py")
        print(f"   2. Revisar gr√°ficas generadas en: resultados/")
        print(f"   3. Generar muestra 5% con: utils.generar_muestra()")
        
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Proceso interrumpido por el usuario")
    except Exception as e:
        print(f"\n‚ùå Error inesperado: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()